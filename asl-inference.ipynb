{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfead9ab",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-30T09:17:26.203293Z",
     "iopub.status.busy": "2023-04-30T09:17:26.202718Z",
     "iopub.status.idle": "2023-04-30T09:18:37.056509Z",
     "shell.execute_reply": "2023-04-30T09:18:37.054925Z"
    },
    "papermill": {
     "duration": 70.866474,
     "end_time": "2023-04-30T09:18:37.059551",
     "exception": false,
     "start_time": "2023-04-30T09:17:26.193077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mtorch.onnx.producer_version 1.13.0\n",
      "tflite_runtime.__version__ 2.11.0\n",
      "tf.__version__ 2.11.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import onnx\n",
    "    import onnxruntime\n",
    "    import tflite_runtime.interpreter as tflite\n",
    "    import onnxsim\n",
    "except:\n",
    "    !pip install tflite-runtime > /dev/null\n",
    "    !pip install onnxruntime-gpu > /dev/null\n",
    "    !pip install onnx-tf > /dev/null\n",
    "    !pip install onnxsim > /dev/null\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json \n",
    "\n",
    "import torch.onnx\n",
    "print('torch.onnx.producer_version', torch.onnx.producer_version)\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import onnxsim\n",
    "\n",
    "import tflite_runtime.interpreter as tflite\n",
    "# kaggle requirement TensorFlow Lite Runtime v2.9.1.\n",
    "\n",
    "import tflite_runtime\n",
    "print('tflite_runtime.__version__', tflite_runtime.__version__)\n",
    "\n",
    "import tensorflow as tf\n",
    "print('tf.__version__', tf.__version__)\n",
    "\n",
    "# import onnx2tf\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# from all import *\n",
    "import torch\n",
    "# from common import *\n",
    "import tensorflow as tf\n",
    "import subprocess\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import onnxsim\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5488e8ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:18:37.075054Z",
     "iopub.status.busy": "2023-04-30T09:18:37.074190Z",
     "iopub.status.idle": "2023-04-30T09:18:37.080894Z",
     "shell.execute_reply": "2023-04-30T09:18:37.079557Z"
    },
    "papermill": {
     "duration": 0.017675,
     "end_time": "2023-04-30T09:18:37.083587",
     "exception": false,
     "start_time": "2023-04-30T09:18:37.065912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_files = [\n",
    "'/kaggle/input/asl-dataset/models_exp81/models_exp81/asl_model_fold0.pth',\n",
    "'/kaggle/input/asl-dataset/models_exp81/models_exp81/asl_model_fold4.pth',\n",
    "'/kaggle/input/asl-dataset/models_exp81/models_exp81/asl_model_fold8.pth',\n",
    "'/kaggle/input/asl-dataset/models_exp81/models_exp81/asl_model_fold9.pth',\n",
    "'/kaggle/input/asl-dataset/models_exp81/models_exp81/asl_model_fold10.pth',\n",
    "'/kaggle/input/asl-dataset/models_exp81/models_exp81/asl_model_fold18.pth',\n",
    "]\n",
    "name = 'exp81'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d42020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:18:37.097570Z",
     "iopub.status.busy": "2023-04-30T09:18:37.097118Z",
     "iopub.status.idle": "2023-04-30T09:18:37.106736Z",
     "shell.execute_reply": "2023-04-30T09:18:37.105364Z"
    },
    "papermill": {
     "duration": 0.019593,
     "end_time": "2023-04-30T09:18:37.109327",
     "exception": false,
     "start_time": "2023-04-30T09:18:37.089734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Config \n",
    "num_landmark = 543\n",
    "max_length = 256\n",
    "num_class  = 250\n",
    "num_point  = 1050 #960 #82  # LIP, LHAND, RHAND\n",
    "\n",
    "embed_dim = 384 #512\n",
    "num_block = 1\n",
    "num_head = 8\n",
    "\n",
    "convert_dir = 'convert_dir' #f'{fold_dir}/convert/{name}'\n",
    "os.makedirs(convert_dir, exist_ok=True)\n",
    "\n",
    "fold = 'all'\n",
    "input_net_k_tf_file = f'{convert_dir}/input_net.fold_{fold}.k.tf'\n",
    "input_net_k_tflite_file = f'{convert_dir}/input_net.fold_{fold}.k.tflite'\n",
    "\n",
    "ROWS_PER_FRAME = 543\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f7476b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:18:37.124599Z",
     "iopub.status.busy": "2023-04-30T09:18:37.124143Z",
     "iopub.status.idle": "2023-04-30T09:18:37.134352Z",
     "shell.execute_reply": "2023-04-30T09:18:37.132985Z"
    },
    "papermill": {
     "duration": 0.02169,
     "end_time": "2023-04-30T09:18:37.137196",
     "exception": false,
     "start_time": "2023-04-30T09:18:37.115506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, hidden_dim),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, embed_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "\n",
    "\n",
    "def positional_encoding(length, embed_dim):\n",
    "    dim = embed_dim//2\n",
    "    position = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    dim = np.arange(dim)[np.newaxis, :]/dim   # (1, dim)\n",
    "    angle = 1 / (10000**dim)         # (1, dim)\n",
    "    angle = position * angle    # (pos, dim)\n",
    "    pos_embed = np.concatenate(\n",
    "        [np.sin(angle), np.cos(angle)],\n",
    "        axis=-1\n",
    "    )\n",
    "    pos_embed = torch.from_numpy(pos_embed).float()\n",
    "    return pos_embed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d218e013",
   "metadata": {
    "papermill": {
     "duration": 0.005941,
     "end_time": "2023-04-30T09:18:37.149381",
     "exception": false,
     "start_time": "2023-04-30T09:18:37.143440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert InputNet to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346ab540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:18:37.164202Z",
     "iopub.status.busy": "2023-04-30T09:18:37.163779Z",
     "iopub.status.idle": "2023-04-30T09:18:37.205970Z",
     "shell.execute_reply": "2023-04-30T09:18:37.204575Z"
    },
    "papermill": {
     "duration": 0.053226,
     "end_time": "2023-04-30T09:18:37.208982",
     "exception": false,
     "start_time": "2023-04-30T09:18:37.155756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class InputNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, ):\n",
    "        super(InputNet, self).__init__()\n",
    "        self.lip = tf.constant([\n",
    "            61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "            291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "            78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "            95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "        ])\n",
    "        self.spose = tf.constant([\n",
    "            504, 502, 500, 501, 503, 505, 512, 513\n",
    "        ])\n",
    "        self.triu_index = tf.constant([\n",
    "            1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n",
    "            14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28,\n",
    "            29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
    "            45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
    "            58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74,\n",
    "            75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 91, 92,\n",
    "            93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 111,\n",
    "            112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
    "            125, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
    "            145, 146, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
    "            166, 167, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
    "            188, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 221,\n",
    "            222, 223, 224, 225, 226, 227, 228, 229, 230, 243, 244, 245, 246,\n",
    "            247, 248, 249, 250, 251, 265, 266, 267, 268, 269, 270, 271, 272,\n",
    "            287, 288, 289, 290, 291, 292, 293, 309, 310, 311, 312, 313, 314,\n",
    "            331, 332, 333, 334, 335, 353, 354, 355, 356, 375, 376, 377, 397,\n",
    "            398, 419,\n",
    "        ])\n",
    "        self.lhand = (468, 489)\n",
    "        self.rhand = (522, 543)\n",
    "        self.max_length = max_length\n",
    "        self.lh = tf.constant([468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488])\n",
    "        self.rh = tf.constant([522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542])\n",
    "    \n",
    "    def do_normalise_by_ref(self, xyz, ref):\n",
    "            \"\"\"Normalises the input array xyz by the reference array ref.\n",
    "\n",
    "            Args:\n",
    "                xyz: The input array to be normalised.\n",
    "                ref: The reference array.\n",
    "\n",
    "            Returns:\n",
    "                The normalised array.\n",
    "            \"\"\"\n",
    "            K = xyz.shape[-1]\n",
    "            xyz_flat = tf.reshape(ref, [-1, K])\n",
    "\n",
    "            m = tf.experimental.numpy.nanmean(xyz_flat, axis=0, keepdims=True)\n",
    "        \n",
    "            denom = tf.experimental.numpy.sum(~tf.experimental.numpy.isnan(xyz_flat),dtype=tf.float32,axis=0,keepdims=True)\n",
    "            std1 = tf.experimental.numpy.nansum(tf.experimental.numpy.square(xyz_flat - m),axis=0,keepdims=True) #, dtype=tf.float32)\n",
    "            s = tf.experimental.numpy.sqrt( std1 / denom)\n",
    "           \n",
    "            xyz = xyz - m\n",
    "            xyz = xyz / s\n",
    "            return xyz\n",
    "\n",
    "\n",
    "    def call(self, xyz):\n",
    "        \n",
    "        L = len(xyz)\n",
    "        if len(xyz) > self.max_length:\n",
    "            # xyz = xyz[:self.max_length] #first\n",
    "            # xyz = xyz[-self.max_length:] #last\n",
    "            i = (L-self.max_length)//2\n",
    "            xyz = xyz[i:i + self.max_length]  # center\n",
    "\n",
    "        L = len(xyz)\n",
    "\n",
    "        REF = tf.concat([self.lip,self.spose, self.lh, self.rh], axis=0)\n",
    "        ref = tf.gather(xyz, REF, axis=1)\n",
    "        xyz = self.do_normalise_by_ref(xyz,ref)\n",
    "\n",
    "        lhand = xyz[:, self.lhand[0]:self.lhand[1],:2]\n",
    "        rhand = xyz[:, self.rhand[0]:self.rhand[1],:2]\n",
    "        ld = tf.reshape(lhand,(-1,21,1,2))-tf.reshape(lhand,(-1,1,21,2))\n",
    "        ld = tf.math.sqrt(tf.reduce_sum((ld ** 2),-1))\n",
    "        ld = tf.reshape(ld,(L, -1))\n",
    "        ld = tf.gather(ld, self.triu_index, axis=1)\n",
    "\n",
    "        rd = tf.reshape(rhand,(-1,21,1,2))-tf.reshape(rhand,(-1,1,21,2))\n",
    "        rd = tf.math.sqrt(tf.reduce_sum((rd ** 2),-1))\n",
    "        rd = tf.reshape(rd,(L, -1))\n",
    "        rd = tf.gather(rd, self.triu_index, axis=1)\n",
    "\n",
    "        xyz = tf.concat([\n",
    "            xyz[:, self.lhand[0]:self.lhand[1]],\n",
    "            xyz[:, self.rhand[0]:self.rhand[1]],\n",
    "            tf.gather(xyz, self.lip, axis=1),\n",
    "            tf.gather(xyz, self.spose, axis=1),\n",
    "        ],1)\n",
    "        dxyz = tf.pad(xyz[:-1] - xyz[1:], [[0, 1], [0, 0], [0, 0]], mode=\"CONSTANT\")\n",
    "        \n",
    "        # Perform calculations\n",
    "        a = xyz[1:, :, 0] - xyz[:-1, :, 0]\n",
    "        b = xyz[1:, :, 1] - xyz[:-1, :, 1]\n",
    "        axyz = tf.sqrt(tf.square(a) + tf.square(b))\n",
    "        axyz = tf.pad(axyz, paddings=[[0, 1], [0, 0]])\n",
    "        \n",
    "        x = tf.concat([\n",
    "            tf.reshape(xyz,(L,-1)),\n",
    "            tf.reshape(dxyz,(L,-1)),\n",
    "            tf.reshape(axyz,(L,-1)),\n",
    "            tf.reshape(rd,(L,-1)),\n",
    "            tf.reshape(ld,(L,-1)),\n",
    "        ], -1)\n",
    "        x = tf.where(tf.math.is_finite(x), x, tf.zeros_like(x))\n",
    "        x = tf.reshape(x, (-1, num_point))\n",
    "\n",
    "        return  x\n",
    "\n",
    "#https://stackoverflow.com/questions/59142040/tensorflow-2-0-how-to-change-the-output-signature-while-using-tf-saved-model\n",
    "class TFModel(tf.Module):\n",
    "    def __init__(self,):\n",
    "        super(TFModel, self).__init__()\n",
    "        self.input_net = InputNet()\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')])\n",
    "    def __call__(self, inputs):\n",
    "        outputs = self.input_net(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49040e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:18:37.223223Z",
     "iopub.status.busy": "2023-04-30T09:18:37.222817Z",
     "iopub.status.idle": "2023-04-30T09:18:39.475290Z",
     "shell.execute_reply": "2023-04-30T09:18:39.473790Z"
    },
    "papermill": {
     "duration": 2.263093,
     "end_time": "2023-04-30T09:18:39.478292",
     "exception": false,
     "start_time": "2023-04-30T09:18:37.215199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converter.converter() passed !!\n"
     ]
    }
   ],
   "source": [
    "def run_convert_input_net_tf():\n",
    "    tf_model = TFModel()\n",
    "    xyz = np.random.rand(15,543,3).astype(np.float32)\n",
    "    x   = tf_model(xyz)\n",
    "\n",
    "    #----\n",
    "    tf_model = TFModel()\n",
    "    tf.saved_model.save(tf_model, input_net_k_tf_file, signatures={\n",
    "        'serving_default': tf_model.__call__,}) #name='inputs'\n",
    "\n",
    "\n",
    "def run_check_input_net():\n",
    "    input_net = InputNet()\n",
    "    xyz = np.random.rand(15,543,3)\n",
    "    x=input_net(xyz)\n",
    "    return x\n",
    "\n",
    "\n",
    "def run_check_input_net_tflite():\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(input_net_k_tf_file)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    with open(input_net_k_tflite_file, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print('converter.converter() passed !!')\n",
    "    \n",
    "    \n",
    "#  main #################################################################\n",
    "if __name__ == '__main__':\n",
    "    x = run_check_input_net() ## x.shape = TensorShape([3, 82, 3])\n",
    "    run_convert_input_net_tf()\n",
    "    run_check_input_net_tflite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca939b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:18:39.493174Z",
     "iopub.status.busy": "2023-04-30T09:18:39.492712Z",
     "iopub.status.idle": "2023-04-30T09:18:39.501751Z",
     "shell.execute_reply": "2023-04-30T09:18:39.500291Z"
    },
    "papermill": {
     "duration": 0.01972,
     "end_time": "2023-04-30T09:18:39.504345",
     "exception": false,
     "start_time": "2023-04-30T09:18:39.484625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([15, 1050])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd16814",
   "metadata": {
    "papermill": {
     "duration": 0.006297,
     "end_time": "2023-04-30T09:18:39.517073",
     "exception": false,
     "start_time": "2023-04-30T09:18:39.510776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert Pytorch Model -> Onnx -> TF Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3567acdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:18:39.532628Z",
     "iopub.status.busy": "2023-04-30T09:18:39.532169Z",
     "iopub.status.idle": "2023-04-30T09:18:39.564541Z",
     "shell.execute_reply": "2023-04-30T09:18:39.563021Z"
    },
    "papermill": {
     "duration": 0.044083,
     "end_time": "2023-04-30T09:18:39.567792",
     "exception": false,
     "start_time": "2023-04-30T09:18:39.523709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyMultiHeadAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "            embed_dim,\n",
    "            out_dim,\n",
    "            qk_dim,\n",
    "            v_dim,\n",
    "            num_head,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_head  = num_head\n",
    "        self.qk_dim = qk_dim\n",
    "        self.v_dim  = v_dim\n",
    "\n",
    "        self.q = nn.Linear(embed_dim, qk_dim*num_head)\n",
    "        self.k = nn.Linear(embed_dim, qk_dim*num_head)\n",
    "        self.v = nn.Linear(embed_dim, v_dim*num_head)\n",
    "\n",
    "        self.out = nn.Linear(v_dim*num_head, out_dim)\n",
    "        self.scale = 1/(qk_dim**0.5)\n",
    "\n",
    "    #https://github.com/pytorch/pytorch/issues/40497\n",
    "    def forward(self, x):\n",
    "        B,L = 1,x.shape[0]\n",
    "        num_head = self.num_head\n",
    "        qk_dim = self.qk_dim\n",
    "        v_dim = self.v_dim\n",
    "\n",
    "        q = self.q(x)\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "        q = q.reshape(L, num_head, qk_dim).permute(1,0,2).contiguous()\n",
    "        k = k.reshape(L, num_head, qk_dim).permute(1,2,0).contiguous()\n",
    "        v = v.reshape(L, num_head, v_dim ).permute(1,0,2).contiguous()\n",
    "\n",
    "        dot = torch.matmul(q, k) *self.scale  # H L L\n",
    "        attn = F.softmax(dot, -1)    # L L\n",
    "        out1 = torch.matmul(attn, v)  \n",
    "        out1 = out1.permute(1,0,2).reshape(L, v_dim*num_head).contiguous()\n",
    "        out1 = self.out(out1)\n",
    "        return out1\n",
    "\n",
    "# remove mask\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "        embed_dim,\n",
    "        num_head,\n",
    "        out_dim,\n",
    "        batch_first=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "#         self.attn  = MultiHeadAttention(embed_dim, num_head,batch_first)\n",
    "        self.attn  = MyMultiHeadAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            out_dim=embed_dim,\n",
    "            qk_dim=embed_dim // num_head,\n",
    "            v_dim=embed_dim // num_head,\n",
    "            num_head=num_head,\n",
    "\n",
    "        )\n",
    "        self.ffn   = FeedForward(embed_dim, out_dim)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(out_dim)\n",
    "\n",
    "    def forward(self, x):             \n",
    "        x = x + self.attn((self.norm1(x))) #[:1]\n",
    "        x = x + self.ffn((self.norm2(x)))\n",
    "        return x\n",
    "    \n",
    "\n",
    "class XEmbed(nn.Module):\n",
    "    def __init__(self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.v = nn.Sequential(\n",
    "            nn.Linear(num_point, embed_dim*2, bias=True),\n",
    "            nn.LayerNorm(embed_dim*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(embed_dim*2, embed_dim, bias=True),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.v(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class SingleNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class=num_class):\n",
    "        super().__init__()\n",
    "        self.num_block = 1\n",
    "        self.embed_dim = 384\n",
    "        self.num_head  = 8\n",
    "        self.max_length = max_length\n",
    "        self.num_point = num_point\n",
    "\n",
    "        pos_embed = positional_encoding(max_length, 16) # self.embed_dim)\n",
    "        self.pos_embed = nn.Parameter(pos_embed)\n",
    "        # Linear layer to map pos_enc_dim to emb_dim\n",
    "        self.pos_enc_linear = nn.Linear(16, embed_dim)\n",
    "\n",
    "        self.cls_embed = nn.Parameter(torch.zeros((1, self.embed_dim)))\n",
    "        self.x_embed=XEmbed()\n",
    "\n",
    "        self.encoder = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                self.embed_dim,\n",
    "                self.num_head,\n",
    "                self.embed_dim,\n",
    "                batch_first=False\n",
    "            ) for i in range(self.num_block)\n",
    "        ])\n",
    "        \n",
    "        self.seq_layer = nn.Sequential(\n",
    "            nn.Linear(embed_dim*2, embed_dim),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.class_layer = nn.Linear(embed_dim, num_class)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, xyz):\n",
    "        x = xyz\n",
    "        L = xyz.shape[0]\n",
    "        x_embed = self.x_embed(xyz.flatten(1)) \n",
    "        x = x_embed[:L] + self.pos_enc_linear(self.pos_embed[:L]) #self.pos_embed[:L]\n",
    "        x = torch.cat([\n",
    "            self.cls_embed,\n",
    "            x\n",
    "        ],0)\n",
    "        \n",
    "        for block in self.encoder:\n",
    "            x = block(x) #,x_mask)\n",
    "        x = F.dropout(x,p=0.4,training=self.training)\n",
    "        \n",
    "        last = torch.mean(x,0).unsqueeze(0)\n",
    "        \n",
    "        x = torch.cat([x[[0]],last],1)\n",
    "        \n",
    "        x = self.seq_layer(x)\n",
    "        x = F.dropout(x,p=0.3, training=self.training)\n",
    "        logit = self.class_layer(x)\n",
    "\n",
    "        return logit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c5ff7d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:18:39.582519Z",
     "iopub.status.busy": "2023-04-30T09:18:39.582061Z",
     "iopub.status.idle": "2023-04-30T09:18:39.799339Z",
     "shell.execute_reply": "2023-04-30T09:18:39.797892Z"
    },
    "papermill": {
     "duration": 0.22801,
     "end_time": "2023-04-30T09:18:39.802194",
     "exception": false,
     "start_time": "2023-04-30T09:18:39.574184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 250])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_net = SingleNet()\n",
    "single_net.eval()\n",
    "x = torch.rand((12,1050))\n",
    "single_net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d69c6845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:18:39.818610Z",
     "iopub.status.busy": "2023-04-30T09:18:39.818160Z",
     "iopub.status.idle": "2023-04-30T09:19:08.903587Z",
     "shell.execute_reply": "2023-04-30T09:19:08.901830Z"
    },
    "papermill": {
     "duration": 29.096423,
     "end_time": "2023-04-30T09:19:08.906384",
     "exception": false,
     "start_time": "2023-04-30T09:18:39.809961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "torch.onnx.export() passed !!\n",
      "onnx simplify() passed !!\n",
      "tf_rep.export_graph() passed !!\n",
      "<All keys matched successfully>\n",
      "torch.onnx.export() passed !!\n",
      "onnx simplify() passed !!\n",
      "tf_rep.export_graph() passed !!\n",
      "<All keys matched successfully>\n",
      "torch.onnx.export() passed !!\n",
      "onnx simplify() passed !!\n",
      "tf_rep.export_graph() passed !!\n",
      "<All keys matched successfully>\n",
      "torch.onnx.export() passed !!\n",
      "onnx simplify() passed !!\n",
      "tf_rep.export_graph() passed !!\n",
      "<All keys matched successfully>\n",
      "torch.onnx.export() passed !!\n",
      "onnx simplify() passed !!\n",
      "tf_rep.export_graph() passed !!\n",
      "<All keys matched successfully>\n",
      "torch.onnx.export() passed !!\n",
      "onnx simplify() passed !!\n",
      "tf_rep.export_graph() passed !!\n"
     ]
    }
   ],
   "source": [
    "tf_file = f'{convert_dir}/tf'\n",
    "tflite_file = f'{convert_dir}/{name}.tflite'\n",
    "\n",
    "def run_convert_tf(single_onnx_file, single_tf_file):\n",
    "    tf_rep = prepare(onnx.load(single_onnx_file))\n",
    "    tf_rep.export_graph(single_tf_file)\n",
    "    print('tf_rep.export_graph() passed !!')\n",
    "    \n",
    "def run_convert_onnx(single_net, single_onnx_file):\n",
    "    single_tensor = torch.zeros(max_length,num_point)\n",
    "    torch.onnx.export(\n",
    "        single_net,                   # model being run\n",
    "        single_tensor,                # model input (or a tuple for multiple inputs)\n",
    "        single_onnx_file,             # where to save the model (can be a file or file-like object)\n",
    "        export_params = True,         # store the trained parameter weights inside the model file\n",
    "        opset_version = 12,#12,       # the ONNX version to export the model to\n",
    "        do_constant_folding=True,     # whether to execute constant folding for optimization\n",
    "        input_names =  ['inputs'],    # the model's input names\n",
    "        output_names = ['outputs'],   # the model's output names\n",
    "        dynamic_axes={\n",
    "            'inputs': {0: 'length'},\n",
    "        },\n",
    "        #verbose = True,\n",
    "    )\n",
    "    print('torch.onnx.export() passed !!')\n",
    "    \n",
    "    for f in [single_onnx_file]:\n",
    "        if f is None: continue\n",
    "        model = onnx.load(f)\n",
    "        onnx.checker.check_model(model)\n",
    "        model_simple, check = onnxsim.simplify(model)\n",
    "        onnx.save(model_simple, f)\n",
    "    print('onnx simplify() passed !!')\n",
    "    \n",
    "\n",
    "for fold, cfile in enumerate(checkpoint_files):\n",
    "    single_net = SingleNet()\n",
    "    if cfile is not None:\n",
    "        f = torch.load(cfile, map_location=lambda storage, loc: storage)\n",
    "        state_dict = f['model']\n",
    "        state_dict['pos_embed'] = state_dict['pos_embed'][:max_length]\n",
    "        print(single_net.load_state_dict(state_dict, strict=False))  # True  False\n",
    "\n",
    "    single_net.eval();\n",
    "    \n",
    "    single_onnx_file = f'{convert_dir}/single_net_fold_{fold}_onnx'\n",
    "    input_tf_file     = f'input_tf_fold_{fold}'\n",
    "    single_tf_file    = f'{convert_dir}/single_tf_fold_{fold}'\n",
    "    \n",
    "    run_convert_onnx(single_net, single_onnx_file)\n",
    "    \n",
    "    run_convert_tf(single_onnx_file, single_tf_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4001c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:19:08.925084Z",
     "iopub.status.busy": "2023-04-30T09:19:08.924640Z",
     "iopub.status.idle": "2023-04-30T09:19:10.037607Z",
     "shell.execute_reply": "2023-04-30T09:19:10.036222Z"
    },
    "papermill": {
     "duration": 1.126495,
     "end_time": "2023-04-30T09:19:10.040780",
     "exception": false,
     "start_time": "2023-04-30T09:19:08.914285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 56384\r\n",
      "drwxr-xr-x 9 root root    4096 Apr 30 09:19 .\r\n",
      "drwxr-xr-x 3 root root    4096 Apr 30 09:18 ..\r\n",
      "drwxr-xr-x 4 root root    4096 Apr 30 09:18 input_net.fold_all.k.tf\r\n",
      "-rw-r--r-- 1 root root   18172 Apr 30 09:18 input_net.fold_all.k.tflite\r\n",
      "-rw-r--r-- 1 root root 9609672 Apr 30 09:18 single_net_fold_0_onnx\r\n",
      "-rw-r--r-- 1 root root 9609672 Apr 30 09:18 single_net_fold_1_onnx\r\n",
      "-rw-r--r-- 1 root root 9609672 Apr 30 09:18 single_net_fold_2_onnx\r\n",
      "-rw-r--r-- 1 root root 9609672 Apr 30 09:18 single_net_fold_3_onnx\r\n",
      "-rw-r--r-- 1 root root 9609672 Apr 30 09:19 single_net_fold_4_onnx\r\n",
      "-rw-r--r-- 1 root root 9609672 Apr 30 09:19 single_net_fold_5_onnx\r\n",
      "drwxr-xr-x 4 root root    4096 Apr 30 09:18 single_tf_fold_0\r\n",
      "drwxr-xr-x 4 root root    4096 Apr 30 09:18 single_tf_fold_1\r\n",
      "drwxr-xr-x 4 root root    4096 Apr 30 09:18 single_tf_fold_2\r\n",
      "drwxr-xr-x 4 root root    4096 Apr 30 09:19 single_tf_fold_3\r\n",
      "drwxr-xr-x 4 root root    4096 Apr 30 09:19 single_tf_fold_4\r\n",
      "drwxr-xr-x 4 root root    4096 Apr 30 09:19 single_tf_fold_5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al convert_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f8780",
   "metadata": {
    "papermill": {
     "duration": 0.007407,
     "end_time": "2023-04-30T09:19:10.056228",
     "exception": false,
     "start_time": "2023-04-30T09:19:10.048821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Convert to TF Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64c26c08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:19:10.074524Z",
     "iopub.status.busy": "2023-04-30T09:19:10.074066Z",
     "iopub.status.idle": "2023-04-30T09:21:10.272052Z",
     "shell.execute_reply": "2023-04-30T09:21:10.270763Z"
    },
    "papermill": {
     "duration": 120.217134,
     "end_time": "2023-04-30T09:21:10.281151",
     "exception": false,
     "start_time": "2023-04-30T09:19:10.064017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.saved_model() passed !!\n",
      "tflite convert() passed !!\n"
     ]
    }
   ],
   "source": [
    "def run_convert_tflite():\n",
    "    single_net_tf_files = [f'{convert_dir}/single_tf_fold_{fold}' for fold in range(len(checkpoint_files))]\n",
    "    \n",
    "    class TFModel(tf.Module):\n",
    "        def __init__(self):\n",
    "            super(TFModel, self).__init__()\n",
    "            self.input_net  = tf.saved_model.load(input_net_k_tf_file)\n",
    "            \n",
    "            self.single_net0 = tf.saved_model.load(single_net_tf_files[0])\n",
    "            self.single_net1 = tf.saved_model.load(single_net_tf_files[1])\n",
    "            self.single_net2 = tf.saved_model.load(single_net_tf_files[2])\n",
    "            self.single_net3 = tf.saved_model.load(single_net_tf_files[3])\n",
    "            self.single_net4 = tf.saved_model.load(single_net_tf_files[4])\n",
    "            self.single_net5 = tf.saved_model.load(single_net_tf_files[5])\n",
    "            \n",
    "            self.input_net.trainable = False\n",
    "            self.single_net0.trainable = False\n",
    "            self.single_net1.trainable = False\n",
    "            self.single_net2.trainable = False\n",
    "            self.single_net3.trainable = False\n",
    "            self.single_net4.trainable = False\n",
    "            self.single_net5.trainable = False\n",
    "            \n",
    "        @tf.function(input_signature=[\n",
    "            tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')\n",
    "        ])\n",
    "        def call(self, inputs):\n",
    "            y = {}\n",
    "            \n",
    "            x  = self.input_net(inputs)\n",
    "            \n",
    "            y0 = self.single_net0(inputs=x)['outputs']\n",
    "            y1 = self.single_net1(inputs=x)['outputs']\n",
    "            y2 = self.single_net2(inputs=x)['outputs']\n",
    "            y3 = self.single_net3(inputs=x)['outputs']\n",
    "            y4 = self.single_net4(inputs=x)['outputs']\n",
    "            y5 = self.single_net5(inputs=x)['outputs']\n",
    "            \n",
    "            outputs = (y0 + y1 + y2 + y3 + y4 + y5 )/6.\n",
    "#             outputs = (y0 + y1 + y2 + y3 + y4 )/5.\n",
    "#             outputs = (y0 + y1)/2.0\n",
    "#             outputs = y0\n",
    "#             outputs = (y0 + y1 + y2)/3.0\n",
    "#             outputs = (y0 + y1 + y3 + y2 )/4.\n",
    "            return {'outputs': outputs }\n",
    "    \n",
    "    \n",
    "    tfmodel = TFModel()\n",
    "    tf.saved_model.save(tfmodel, tf_file, signatures={'serving_default': tfmodel.call})\n",
    "    print('tf.saved_model() passed !!')\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(tf_file)\n",
    "    # converter.target_spec.supported_ops = [\n",
    "    #     tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    #     tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "    # ]\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "    #converter.allow_custom_ops = True\n",
    "    #converter.experimental_new_converter = True\n",
    "    tf_lite_model = converter.convert()\n",
    "    with open(tflite_file, 'wb') as f:\n",
    "        f.write(tf_lite_model)\n",
    "    print('tflite convert() passed !!')\n",
    "    \n",
    "        \n",
    "run_convert_tflite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae1851b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:21:10.299092Z",
     "iopub.status.busy": "2023-04-30T09:21:10.297888Z",
     "iopub.status.idle": "2023-04-30T09:21:12.179645Z",
     "shell.execute_reply": "2023-04-30T09:21:12.178240Z"
    },
    "papermill": {
     "duration": 1.893804,
     "end_time": "2023-04-30T09:21:12.182573",
     "exception": false,
     "start_time": "2023-04-30T09:21:10.288769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input_details : [{'name': 'serving_default_inputs:0', 'index': 0, 'shape': array([  1, 543,   3], dtype=int32), 'shape_signature': array([ -1, 543,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "input_shape   : [  1 543   3]\n",
      "output_shape  : [  1 250]\n",
      "\n",
      "found_signatures : ['serving_default']\n",
      "\n",
      " *** debug tflite runtime ***\n",
      "------------------------------\n",
      "xyz  : (3, 543, 3)\n",
      "y    : (1, 250)\n",
      "xyz NaN   : 189\n",
      "xyz values: [ 0.5168196   0.482137   -0.04360763  0.5173948   0.43922532]\n",
      "y   values: [-0.3382505  -0.6208968  -0.33524254 -0.08385886 -0.34519818]\n",
      "y   top5  : [238 248 132 195 166]\n",
      "truth     : 238 white\n",
      "\n",
      "------------------------------\n",
      "xyz  : (11, 543, 3)\n",
      "y    : (1, 250)\n",
      "xyz NaN   : 1260\n",
      "xyz values: [ 0.57777625  0.5093604  -0.05024542  0.572079    0.47016424]\n",
      "y   values: [-0.52848387 -0.49910167 -0.5533188  -0.33282503 -0.4135931 ]\n",
      "y   top5  : [232 147 216  20  28]\n",
      "truth     : 232 wait\n",
      "\n",
      "------------------------------\n",
      "xyz  : (15, 543, 3)\n",
      "y    : (1, 250)\n",
      "xyz NaN   : 1008\n",
      "xyz values: [ 0.48299694  0.45240664 -0.04374029  0.47620538  0.41290924]\n",
      "y   values: [-0.33797356 -0.4957995  -0.3695378  -0.37528276 -0.09285041]\n",
      "y   top5  : [162 159  37  67 158]\n",
      "truth     : 162 orange\n",
      "\n",
      "------------------------------\n",
      "xyz  : (23, 543, 3)\n",
      "y    : (1, 250)\n",
      "xyz NaN   : 2205\n",
      "xyz values: [ 0.49440014  0.38046983 -0.03062646  0.49601725  0.3507348 ]\n",
      "y   values: [-0.235946   -0.27973062 -0.18228908 -0.17779244 -0.12990582]\n",
      "y   top5  : [ 25  14 128  86 168]\n",
      "truth     : 25 blow\n",
      "\n",
      "------------------------------\n",
      "xyz  : (105, 543, 3)\n",
      "y    : (1, 250)\n",
      "xyz NaN   : 11466\n",
      "xyz values: [ 0.4378861   0.43759912 -0.05113366  0.4432577   0.39290097]\n",
      "y   values: [-0.4238054  -0.01087701  0.14156659 -0.44300756  0.78601366]\n",
      "y   top5  : [ 48 112   4 146 137]\n",
      "truth     : 48 cloud\n",
      "\n",
      "------------------------------\n",
      "xyz  : (141, 543, 3)\n",
      "y    : (1, 250)\n",
      "xyz NaN   : 12159\n",
      "xyz values: [ 0.56025726  0.3877466  -0.04065609  0.5534039   0.35289925]\n",
      "y   values: [-0.10471956 -0.21976544 -0.15266363  0.2368823   0.00133748]\n",
      "y   top5  : [144  35 244 141   3]\n",
      "truth     : 144 mitten\n",
      "\n",
      "------------------------------\n",
      "xyz  : (154, 543, 3)\n",
      "y    : (1, 250)\n",
      "xyz NaN   : 19152\n",
      "xyz values: [ 0.61352694  0.43049398 -0.06657115  0.61146456  0.3962365 ]\n",
      "y   values: [-0.38357225 -0.53979075 -0.20929025  0.13069674  0.45146137]\n",
      "y   top5  : [ 42 160 183  45  33]\n",
      "truth     : 42 child\n",
      "\n",
      "------------------------------\n",
      "xyz  : (225, 543, 3)\n",
      "y    : (1, 250)\n",
      "xyz NaN   : 19152\n",
      "xyz values: [ 0.49103034  0.3451965  -0.04031543  0.48127457  0.31263527]\n",
      "y   values: [-0.2900613  -0.1477539  -0.05759356 -0.44136104  0.30522746]\n",
      "y   top5  : [ 48 112  14 183  29]\n",
      "truth     : 48 cloud\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 1: ##debug\n",
    "    DF_INDEX = [\n",
    "    180     ,#train_landmark_files/4718/1007273104.parquet,4718,1007273104,white,3\n",
    "    1       ,#train_landmark_files/28656/1000106739.parquet,28656,1000106739,wait,11\n",
    "    81543   ,#train_landmark_files/2044/4693753.parquet,2044,4693753,orange,15\n",
    "    0       ,#train_landmark_files/26734/1000035562.parquet,26734,1000035562,blow,23\n",
    "    2       ,#train_landmark_files/16069/100015657.parquet,16069,100015657,cloud,105\n",
    "    13      ,#train_landmark_files/26734/1000661926.parquet,26734,1000661926,mitten,141\n",
    "    4622    ,#train_landmark_files/28656/1192107487.parquet,28656,1192107487,child,154\n",
    "    45      ,#train_landmark_files/26734/1001931356.parquet,26734,1001931356,cloud,225\n",
    "    ]\n",
    "    sign_to_label = json.load(open(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\", \"r\"))\n",
    "    kaggle_df = pd.read_csv('/kaggle/input/asl-folds/asl_train_5folds_sgkf.csv') #f'{root_dir}/data/asl-signs/train.ver01.csv')\n",
    "    kaggle_df.loc[:, 'label'] = kaggle_df.sign.map(sign_to_label)\n",
    "\n",
    "\n",
    "    interpreter = tflite.Interpreter(tflite_file)\n",
    "\n",
    "    #---\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    input_shape  = input_details[0]['shape']\n",
    "    output_shape = output_details[0]['shape']\n",
    "    print('')\n",
    "    print('input_details :', input_details)\n",
    "    print('input_shape   :', input_shape)\n",
    "    print('output_shape  :', output_shape)\n",
    "    print('')\n",
    "\n",
    "    #---\n",
    "\n",
    "    found_signatures = list(interpreter.get_signature_list().keys())\n",
    "    print('found_signatures :', found_signatures)\n",
    "\n",
    "    # if REQUIRED_SIGNATURE not in found_signatures:\n",
    "    # \traise KernelEvalException('Required input signature not found.')\n",
    "\n",
    "    prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "    ##todo lite api to print tflite model spec\n",
    "    print('')\n",
    "    print(' *** debug tflite runtime ***')\n",
    "    for i in DF_INDEX: # * 10000:\n",
    "        d = kaggle_df.iloc[i]\n",
    "        pq_file = f'/kaggle/input/asl-signs/{d.path}'\n",
    "        xyz = load_relevant_data_subset(pq_file)\n",
    "        output = prediction_fn(inputs=xyz)#[:98]\n",
    "\n",
    "        y = output['outputs']\n",
    "        xyz_flat = xyz.reshape(-1)\n",
    "        y_flat = y.reshape(-1)\n",
    "\n",
    "        # print(d)\n",
    "        print('------------------------------')\n",
    "        print('xyz  :', xyz.shape)\n",
    "        print('y    :', y.shape)\n",
    "        print('xyz NaN   :', np.isnan(xyz_flat).sum())\n",
    "        print('xyz values:', xyz_flat[:5])\n",
    "        print('y   values:', y_flat[:5])\n",
    "        print('y   top5  :', np.argsort(-y_flat)[:5])\n",
    "        print('truth     :', d.label, d.sign)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb596a2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:21:12.201655Z",
     "iopub.status.busy": "2023-04-30T09:21:12.200450Z",
     "iopub.status.idle": "2023-04-30T09:21:16.122852Z",
     "shell.execute_reply": "2023-04-30T09:21:16.121577Z"
    },
    "papermill": {
     "duration": 3.935205,
     "end_time": "2023-04-30T09:21:16.126038",
     "exception": false,
     "start_time": "2023-04-30T09:21:12.190833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import ok\n",
      "  adding: model.tflite (deflated 8%)\r\n",
      "total 54288\r\n",
      "----------  1 root root    53613 Apr 30 09:21 __notebook__.ipynb\r\n",
      "drwxr-xr-x 10 root root     4096 Apr 30 09:21 convert_dir\r\n",
      "-rw-r--r--  1 root root 28928612 Apr 30 09:21 model.tflite\r\n",
      "-rw-r--r--  1 root root 26595980 Apr 30 09:21 submission.zip\r\n",
      "tflite_file: convert_dir/exp81.tflite\n",
      "submit ok\n"
     ]
    }
   ],
   "source": [
    "# tflite_file = '/kaggle/working/exp3.tflite'\n",
    "# '/kaggle/input/asl-demo/run20-aug3-xyz2.tflite'\n",
    "\n",
    "mode = 'submit' #debug #submit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "print('import ok')\n",
    "'''\n",
    "Your model must also require less than 40 MB in memory and \n",
    "perform inference with less than 100 milliseconds of latency per video. \n",
    "Expect to see approximately 40,000 videos in the test set. \n",
    "We allow an additional 10 minute buffer for loading the data and miscellaneous overhead.\n",
    "\n",
    "'''\n",
    "def time_to_str(t, mode='min'):\n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "shutil.copyfile(tflite_file, 'model.tflite') \n",
    "!zip submission.zip  'model.tflite'\n",
    "!ls -l\n",
    "\n",
    "print('tflite_file:', tflite_file)\n",
    "print(f'submit ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae19a5cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T09:21:16.146701Z",
     "iopub.status.busy": "2023-04-30T09:21:16.145740Z",
     "iopub.status.idle": "2023-04-30T09:21:16.151238Z",
     "shell.execute_reply": "2023-04-30T09:21:16.150116Z"
    },
    "papermill": {
     "duration": 0.018858,
     "end_time": "2023-04-30T09:21:16.154021",
     "exception": false,
     "start_time": "2023-04-30T09:21:16.135163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf convert_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa169ad",
   "metadata": {
    "papermill": {
     "duration": 0.008191,
     "end_time": "2023-04-30T09:21:16.170785",
     "exception": false,
     "start_time": "2023-04-30T09:21:16.162594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 243.895041,
   "end_time": "2023-04-30T09:21:18.901965",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-30T09:17:15.006924",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
